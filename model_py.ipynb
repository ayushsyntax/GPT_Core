{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTRgUyIylEQY+7I8ZapgeG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z05dzY9WaWAA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class Head(nn.Module):\n",
        "  def __init__(self,head_size,n_embd,block_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embd,head_size,bias= False)\n",
        "    self.query= nn.Linear(n_embd,head_size,bias= False)\n",
        "    self.value = nn.Linear(n_embd,head_size,bias= False)\n",
        "    self.register_buffer('tril',torch.tril(torch.ones(block_size,block_size)))\n",
        "  def forward(self,x):\n",
        "    B,T,C = x.shape\n",
        "    k = self.key(x)\n",
        "    q = self.query(x)\n",
        "    wei = q@k.transpose(-2,-1)*(C**-0.5)\n",
        "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "    wei = F.softmax(wei,dim=-1)\n",
        "    v = self.value(x)\n",
        "    return wei @ v ,wei\n",
        ""
      ]
    }
  ]
}